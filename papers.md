---
layout: page
title: MATH-AI
subtitle: "The 5th Workshop on Mathematical Reasoning and AI"
use-site-title: true
---
<div class="venue" style="font-size: 27px; display: block; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-weight: 300; color: #404040; text-align: center;">
  (Upper Level Ballroom 6A, San Diego Convention Center, December 6, 2025, <a href="https://neurips.cc/Conferences/2025" target="_blank">Website</a>)
</div>

# Accepted Papers

<ol>
    <li>Tales from a Graph: a Pipeline for Mathematical Problem Generation</li>
    <li>Meta Thinker: Thinking What AI Thinks</li>
    <li>SATBench: Benchmarking LLMs&#x27; Logical Reasoning via Automated Puzzle Generation from SAT Formulas</li>
    <li>Probabilistic Soundness Guarantees in LLM Reasoning Chains</li>
    <li>I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models</li>
    <li>Axiom-Aware FunSearch for Non-Constructive Mathematics</li>
    <li>CauSciBench: Assessing LLM Causal Reasoning for Scientific Research</li>
    <li>PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning</li>
    <li>Aryabhata: An exam-focused language model for JEE Math</li>
    <li>Scratchpad Thinking: Alternation Between Storage and Computation in Latent Reasoning Models</li>
    <li>Curiosity-driven RL for symbolic equation solving</li>
    <li>Decompose, Adapt, and Evolve: Towards Efficient Scientific Equation Discovery with Large Language Models</li>
    <li>Adaptive Coopetition: Leveraging Coarse Verifier Signals for Resilient Multi-Agent LLM Reasoning</li>
    <li>Infinite-Dimensional HiPPO Provides an Explicit Formula for LSSLs</li>
    <li>MathSticks: A Benchmark for Visual Symbolic Compositional Reasoning with Matchstick Puzzles</li>
    <li>ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models</li>
    <li>Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What to Use Instead</li>
    <li>Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles</li>
    <li>Towards Scaling Laws for Symbolic Regression</li>
    <li>Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning</li>
    <li>Minif2f in Rocq: Automatic Translation Between Proof Assistants — A Case Study</li>
    <li>OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL Cycles</li>
    <li>EchoRL: Learning to Plan through Experience for Efficient Reinforcement Learning</li>
    <li>Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs</li>
    <li>CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models</li>
    <li>DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning</li>
    <li>RADAR: Reasoning–Ability and Difficulty-Aware Routing for Reasoning LLMs</li>
    <li>Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision</li>
    <li>TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models</li>
    <li>Decoupling Reasoning from Proving: A New Framework for Tackling Olympiad-Level Mathematics</li>
    <li>Analytical Lyapunov Function Discovery: An RL-based Generative Approach</li>
    <li>You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models</li>
    <li>PVSGym: A Proof Learning Environment</li>
    <li>ProxyThinker: Test-Time Guidance through Small Visual Reasoners</li>
    <li>Nested Depth Generalization in Transformers</li>
    <li>Learning Modular Exponentiation with Transformers</li>
    <li>\textsc{Gambit}: Generating Automated Mathematical Bounds, Inequalities, and Theorems</li>
    <li>Specifying exact circuit algorithms in universal transformers</li>
    <li>Tool-Assisted Multi-Turn Theorem Proving with LLMs</li>
    <li>A Small Math Model: Recasting Strategy Choice Theory in an LLM-Inspired Architecture</li>
    <li>Solving Inequality Proofs with Large Language Models</li>
    <li>Beyond Accuracy: Evaluating Multimodal Mathematical and Scientific Reasoning Through Error Analysis and Self-Correction</li>
    <li>Process-Verified Reinforcement Learning for Theorem Proving via Lean</li>
    <li>LLM-Generated Search Heuristics Can Solve Open Instances of Combinatorial Design Problems</li>
    <li>Expanding the Action Space of LLMs to Reason Beyond Language</li>
    <li>Single-stream Policy Optimization</li>
    <li>SpotIt: Evaluating Text-to-SQL Evaluation with Formal Verification</li>
    <li>CircuitSense: A Hierarchical Circuit System Benchmark Bridging Visual Comprehension and Symbolic Reasoning in Engineering Design Process</li>
    <li>Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework</li>
    <li>Why Reinforcement Learning Struggles with Expression Simplification: A Reward Analysis</li>
    <li>AI Impact on Human Proof Formalization Workflows</li>
    <li>One Token to Fool LLM-as-a-Judge</li>
    <li>Modeling Chain-of-Thought Collapse in Pruned Language Models: Fidelity and Similarity Analysis for Mathematical Reasoning</li>
    <li>LeanDojo-v2: A Comprehensive Library for AI-Assisted Theorem Proving in Lean</li>
    <li>From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Reasoning-Driven Pedagogical Visualization</li>
    <li>Learning Permuted Congruential Sequences with Transformers</li>
    <li>In-the-Flow Agentic System Optimization for Effective Planning and Tool Use</li>
    <li>SciML Agents: Write the Solver, Not the Solution</li>
    <li>Concept Generalization in Humans and Large Language Models: Insights from the Number Game</li>
    <li>Hilbert: Recursively Building Formal Proofs with Informal Reasoning</li>
    <li>Risk-Sensitive Reinforcement Learning for Alleviating Exploration Dilemmas in Large Language Models</li>
    <li>FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory</li>
    <li>PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier</li>
    <li>Mirage or Method? How Model–Task Alignment Induces Divergent RL Conclusions</li>
    <li>AI-Driven Mathematical Discovery for the Andrews–Curtis Conjecture</li>
    <li>DAG-Math: Graph-Guided Mathematical Reasoning in LLMs</li>
    <li>ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations</li>
    <li>A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models</li>
    <li>Co-rewarding: Stable Self-supervised RL for Eliciting Reasoning in Large Language Models</li>
    <li>On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning</li>
    <li>R-Zero: Self-Evolving Reasoning LLM from Zero Data</li>
    <li>Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward</li>
    <li>Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors</li>
    <li>RLVR vs. Distillation: Understanding Accuracy and Capability in LLM Mathematical Reasoning</li>
    <li>Combining Textual and Structural Information for Premise Selection in Lean</li>
    <li>Improving autoformalization via cycle consistency and incremental type-checking using language-model probabilistic programs</li>
    <li>Beyond Correctness: Harmonizing Process and Outcome Rewards through RL Training</li>
    <li>Adaptive Control for Test-time Scaling</li>
    <li>Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization</li>
    <li>AntiderivBench: Evaluating language models on indefinite integration</li>
    <li>Improving ML attacks on LWE with data repetition and stepwise regression</li>
    <li>Credit Cards, Confusion, Computation, and Consequences: How Well Do LLMs Reason About Financial Literacy?</li>
    <li>Kimina Lean Server: A High-Performance Lean Server for Large-Scale Verification</li>
    <li>Restructuring the Corpus Makes RAG Work for Math</li>
    <li>Numbers Already Carry Their Own Embeddings</li>
    <li>Simultaneous Multi-objective Alignment Across Verifiable and Non-verifiable Rewards</li>
    <li>OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization</li>
    <li>Stoic Reasoner: Dual-Mode Transformers that Compress to Think and Decompress to Speak</li>
    <li>FoCus: Improving Faithfulness in Chain-of-Thoughts by Training on Structured Reasoning Data</li>
    <li>DELTA: How Does RL Unlock and Transfer New Algorithms in LLMs?</li>
    <li>Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection</li>
    <li>MathBode: Understanding LLM Reasoning with Dynamical Systems</li>
    <li>STAT: Skill-Targeted Adaptive Training</li>
    <li>SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers</li>
    <li>Learning How to Use Tools, Not Just When: Pattern-Aware Tool-Integrated Reasoning</li>
    <li>Babel-formal: Translation of Proofs between Lean and Rocq</li>
    <li>HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</li>
    <li>Usefulness-Driven Learning of Formal Mathematics</li>
    <li>Stepwise Guided Policy Optimization: Coloring your Incorrect Reasoning in GRPO</li>
    <li>Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with Bézier Curves</li>
    <li>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</li>
    <li>VeriBench-FTP: A Formal Theorem Proving Benchmark in Lean 4 for Code Verification</li>
    <li>STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision</li>
    <li>HYBRIDMIND: Meta Selection of Natural Language and Symbolic Language for Enhanced LLM Reasoning</li>
    <li>StreetMath: Study of LLMs’ Approximation Behaviors</li>
    <li>Climbing the Ladder of Reasoning: What LLMs Can—and Still Can’t—Solve after SFT?</li>
    <li>Inpainting-Guided Policy Optimization for Diffusion Large Language Models</li>
    <li>How does RL induce skill composition? A Case Study using Countdown</li>
    <li>Blind Spot Navigation in Large Language Model Reasoning with Thought Space Explorer</li>
    <li>CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning</li>
    <li>Pretraining Scaling Laws for Generative Evaluations of Language Models</li>
    <li>RAISE: Enhancing Scientific Reasoning in LLMs via Step-by-Step Retrieval</li>
    <li>Reliable Fine-Grained Evaluation of Natural Language Math Proofs</li>
    <li>SPG: Sandwiched Policy Gradient for Mask Diffusion Language Models</li>
    <li>On the Evolution of Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation</li>
    <li>Measuring Off-Trajectory Math Reasoning of LLMs</li>
    <li>AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time</li>
    <li>Towards Understanding Self-play for LLM Reasoning</li>
    <li>Systematic Diagnosis of Brittle Reasoning in Large Language Models</li>
    <li>Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers</li>
    <li>IMProofBench: Benchmarking AI on Research-Level Mathematical Proof Generation</li>
    <li>Landscape of Thoughts: Visualizing the Reasoning Process of Large Language Models</li>
    <li>Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces</li>
    <li>Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers</li>
    <li>MathNet: a Global Multimodal Benchmark for Mathematical Reasoning and Retrieval</li>
    <li>BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs</li>
    <li>Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning</li>
    <li>Understanding Tool-Integrated Reasoning</li>
    <li>CoDaPO: Confidence and Difficulty-Adaptive Policy Optimization for Language Models</li>
    <li>ProofGym: Unifying LLM-Based Theorem Proving Across Formal Systems</li>
    <li>Unspoken Logic: Understanding and bridging the gap between free-form and LLM-interpretable natural language mathematical proofs</li>
    <li>Evaluating Spatial Reasoning in Language Models</li>
    <li>Faults in our Formal Benchmarks</li>
    <li>CayleyPy Growth: Efficient growth computations and hundreds of new conjectures on Cayley graphs</li>
    <li>In Good GRACES: Principled Teacher Selection for Knowledge Distillation</li>
    <li>Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients</li>
    <li>Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training</li>
    <li>DiagramIR: An Automatic Pipeline for Educational Math Diagram Evaluation</li>
    <li>ARM: Discovering Agentic Reasoning Modules for Mathematical Problem-Solving</li>
    <li>Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation</li>
    <li>Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning</li>
    <li>Reinforcement Learning for Hierarchical Proof Generation in Lean 4</li>
    <li>Exact Learning of Arithmetic with Differentiable Agents</li>
    <li>Think, Align, Select: Query–Key Scores for LLM Reasoning</li>
    <li>FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis</li>
    <li>Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute</li>
    <li>Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains</li>
    <li>A NUMA Aware Compiler Framework for Large Scale Mathematical Reasoning Inference on PCIe Based Multi Accelerator Systems</li>
    <li>Winning Gold at IMO 2025 with a Model-Agnostic Verification-and-Refinement Pipeline</li>
    <li>Learning to Reason on Hard Problems with Privileged On-Policy Exploration</li>
    <li>Patching Gaps In LLM Reasoning With Interventional Training</li>
    <li>A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation</li>
    <li>RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows</li>
</ol>


The list of accepted papers can be found on OpenReview <a href="https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/MATH-AI#tab-accept-poster">here</a>.

# Reviewers

We are grateful to our fantastic reviewers for making our workshop reviewing process run smoothly:

<div class="reviewers">
<ul>
{% for reviewer in site.data.pc.people %}
    <li>{{ reviewer }}</li>
{% endfor %}
</ul>
</div>

<style>
.reviewers ul {
    columns: 4;
    -webkit-columns: 4;
    -moz-columns: 4;
    list-style-position: inside;
    padding-left: 0;
}
.reviewers li {
    break-inside: avoid;
    page-break-inside: avoid;
    padding: 2px 0;
}
</style>
